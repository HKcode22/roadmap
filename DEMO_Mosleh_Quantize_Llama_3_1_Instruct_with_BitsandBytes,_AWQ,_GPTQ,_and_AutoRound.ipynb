{"cells":[{"cell_type":"markdown","metadata":{"id":"SEIDyR0jXHi0"},"source":["This notebook shows how to quantize  models with BitsandBytes, AWQ, GPTQ, and AutoRound.\n","\n","All these quantization methods run on consumer hardware and won't require a GPU with more than 24 GB of VRAM.\n"]},{"cell_type":"markdown","metadata":{"id":"NEAKEvPFs34J"},"source":["#AutoRound"]},{"cell_type":"code","source":["!pip install --upgrade transformers auto-round"],"metadata":{"id":"25Ydu5cYkDXW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n","\n","model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","from auto_round import AutoRound\n","\n","\n","bits, group_size, sym = 4, 128, True\n","autoround = AutoRound(model, tokenizer, bits=bits, group_size=group_size, batch_size=2, seqlen=512, sym=sym, gradient_accumulate_steps=4, device='cuda')\n","autoround.quantize()\n","output_dir = \"./AutoRound/GPTQ-sym/\"\n","autoround.save_quantized(output_dir)"],"metadata":{"id":"HujIHO8z4kM1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.push_to_hub(\"Meta-Llama-3.1-8B-Instruct-autoround-4bit-sym\", token = \"...\")\n","tokenizer.push_to_hub(\"Meta-Llama-3.1-8B-Instruct-autoround-4bit-sym\", token = \"...\")"],"metadata":{"id":"dlHCiMQ85RGh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FD3q568x51xO"},"source":["#GPTQ"]},{"cell_type":"code","source":["\n","!pip install --upgrade auto-gptq accelerate datasets optimum\n","!pip install --upgrade transformers\n"],"metadata":{"id":"T5naxxrUkIIm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","from optimum.gptq import GPTQQuantizer\n","import torch\n","\n","model_path = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n","w = 4 #quantization to 4-bit. Change to 2, 3, or 8 to quantize with another precision\n","\n","quant_path = 'Meta-Llama-3.1-8B-Instruct-gptq-'+str(w)+'bit'\n","\n","# Load model and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n","model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n","\n","quantizer = GPTQQuantizer(bits=w, dataset=\"c4\", model_seqlen = 2048)\n","quantized_model = quantizer.quantize_model(model, tokenizer)\n","\n","quantized_model.save_pretrained(\".//GPTQ/\"+quant_path, safetensors=True)\n","tokenizer.save_pretrained(\"./GPTQ/\"+quant_path)"],"metadata":{"id":"5VDbtM3P5gux"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w6h5mowHMAv6"},"source":["#Bitsandbytes\n","\n"]},{"cell_type":"code","source":["!pip install -U bitsandbytes\n"],"metadata":{"id":"DzS61QH_kJlj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","if torch.cuda.is_bf16_supported():\n","  compute_dtype = torch.bfloat16\n","else:\n","  compute_dtype = torch.float16\n","\n","model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n","quant_path = 'Meta-Llama-3.1-8B-Instruct-bnb-4bit'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","bnb_config = BitsAndBytesConfig(\n","        load_in_4bit=True,\n","        bnb_4bit_quant_type=\"nf4\",\n","        bnb_4bit_compute_dtype=compute_dtype,\n","        bnb_4bit_use_double_quant=True,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","          model_name, quantization_config=bnb_config\n",")\n","model.save_pretrained(\"./BnB/\"+quant_path, safetensors=True)\n","tokenizer.save_pretrained(\"./BnB/\"+quant_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["b60af1e5fece432889d0354a26d9b9e8","5e464305d9c94ea08e082eb1d6579443","6915055a3e114482909fc2315fdb4b56","0697b0d1616e46eeacd96e025e08a659","5f3da801157942f7ae51bbe7ae48d0b1","97593667e9bc4e48b061edfe86b32b53","912d7923528d4038a91a8c130ebd3da7","3d4620d579b94d6ca2e6f08879b6cba0","85c790dde6544d96b2e53bad49701947","bb73c96c8c114adb8432b815a7f96522","1ff3cb5e09dc41c3b0bcc6d4fee55684"]},"id":"v1R7ws-s6Xc8","outputId":"df142966-e609-4a38-c77a-7e1317c396f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b60af1e5fece432889d0354a26d9b9e8"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["('./BnB/Meta-Llama-3.1-8B-Instruct-bnb-4bit/tokenizer_config.json',\n"," './BnB/Meta-Llama-3.1-8B-Instruct-bnb-4bit/special_tokens_map.json',\n"," './BnB/Meta-Llama-3.1-8B-Instruct-bnb-4bit/tokenizer.json')"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"Q-SOLg5KNFCJ"},"source":["#AWQ"]},{"cell_type":"code","source":["!pip install --upgrade autoawq optimum accelerate torch\n","!pip install --upgrade transformers"],"metadata":{"id":"8j6KdwZwkLVQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","from awq import AutoAWQForCausalLM\n","\n","model_path = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n","quant_path = 'Meta-Llama-3.1-8B-Instruct-awq-4bit'\n","quant_config = { \"zero_point\": True, \"q_group_size\": 128, \"w_bit\": 4, \"version\": \"GEMM\" }\n","\n","\n","# Load model and tokenizer\n","model = AutoAWQForCausalLM.from_pretrained(model_path, safetensors=True, device_map='cuda')\n","tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n","\n","\n","# Quantize\n","model.quantize(tokenizer, quant_config=quant_config)\n","\n","# Save quantized model with safetensors\n","model.save_quantized(\"./AWQ/\"+quant_path, safetensors=True)\n","tokenizer.save_pretrained(\"./AWQ/\"+quant_path)\n","\n"],"metadata":{"id":"9DGx9I1a65-s"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b60af1e5fece432889d0354a26d9b9e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e464305d9c94ea08e082eb1d6579443","IPY_MODEL_6915055a3e114482909fc2315fdb4b56","IPY_MODEL_0697b0d1616e46eeacd96e025e08a659"],"layout":"IPY_MODEL_5f3da801157942f7ae51bbe7ae48d0b1"}},"5e464305d9c94ea08e082eb1d6579443":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97593667e9bc4e48b061edfe86b32b53","placeholder":"​","style":"IPY_MODEL_912d7923528d4038a91a8c130ebd3da7","value":"Loading checkpoint shards: 100%"}},"6915055a3e114482909fc2315fdb4b56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d4620d579b94d6ca2e6f08879b6cba0","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85c790dde6544d96b2e53bad49701947","value":4}},"0697b0d1616e46eeacd96e025e08a659":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb73c96c8c114adb8432b815a7f96522","placeholder":"​","style":"IPY_MODEL_1ff3cb5e09dc41c3b0bcc6d4fee55684","value":" 4/4 [00:10&lt;00:00,  2.28s/it]"}},"5f3da801157942f7ae51bbe7ae48d0b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97593667e9bc4e48b061edfe86b32b53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"912d7923528d4038a91a8c130ebd3da7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d4620d579b94d6ca2e6f08879b6cba0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85c790dde6544d96b2e53bad49701947":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb73c96c8c114adb8432b815a7f96522":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ff3cb5e09dc41c3b0bcc6d4fee55684":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}